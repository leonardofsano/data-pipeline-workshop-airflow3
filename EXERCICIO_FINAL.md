# Exerc√≠cio Final - Pipeline de Dados de Produtos

## üéØ Objetivo
Criar um pipeline ETL completo para processar dados de produtos e vendas, aplicando os conceitos aprendidos na aula.

## üìã Cen√°rio
Voc√™ trabalha como engenheiro de dados em uma empresa de e-commerce. Precisa criar um pipeline que processe dados de produtos vindos de diferentes fontes e gere relat√≥rios consolidados.

## üìä Dados Fornecidos

### Arquivo: `produtos_loja.csv`
```csv
ID_Produto,Nome_Produto,Categoria,Preco_Custo,Fornecedor,Status
P001,Notebook Dell,Eletr√¥nicos,2500.00,Dell Inc,Ativo
P002,Mouse Logitech,Acess√≥rios,45.50,Logitech,Ativo
P003,Teclado Mec√¢nico,Acess√≥rios,,Razer,Inativo
P004,Monitor 24",Eletr√¥nicos,800.00,Samsung,Ativo
P005,Webcam HD,Acess√≥rios,120.00,,Ativo
```

### Arquivo: `vendas_produtos.csv`
```csv
ID_Venda,ID_Produto,Quantidade_Vendida,Preco_Venda,Data_Venda,Canal_Venda
V001,P001,2,3200.00,2024-01-15,Online
V002,P002,5,55.00,2024-01-15,Loja F√≠sica
V003,P001,1,3200.00,2024-01-16,Online
V004,P004,3,950.00,2024-01-16,Online
V005,P002,10,,2024-01-17,Loja F√≠sica
```

## üöÄ Tarefas do Exerc√≠cio

### Parte 1: An√°lise e Planejamento
1. **Identifique os problemas nos dados:**
   - Quais campos t√™m valores nulos?
   - Que transforma√ß√µes s√£o necess√°rias?

2. **Defina a estrat√©gia ETL:**
   - Qual abordagem usar: ETL ou ELT? Justifique.
   - Que transforma√ß√µes aplicar?

### Parte 2: Implementa√ß√£o da DAG
Crie uma DAG chamada `pipeline_produtos_vendas` com as seguintes tarefas:

#### Task 1: `extract_produtos`
- Ler arquivo `produtos_loja.csv`
- Validar se o arquivo existe
- Log do n√∫mero de registros extra√≠dos

#### Task 2: `extract_vendas`
- Ler arquivo `vendas_produtos.csv`
- Validar se o arquivo existe
- Log do n√∫mero de registros extra√≠dos

#### Task 3: `transform_data`
- **Limpeza de dados:**
  - Preencher `Preco_Custo` nulo com m√©dia da categoria
  - Preencher `Fornecedor` nulo com "N√£o Informado"
  - Preencher `Preco_Venda` nulo com `Preco_Custo * 1.3`

- **Transforma√ß√µes:**
  - Calcular `Receita_Total` = `Quantidade_Vendida * Preco_Venda`
  - Calcular `Margem_Lucro` = `Preco_Venda - Preco_Custo`
  - Criar campo `Mes_Venda` extra√≠do de `Data_Venda`

#### Task 4: `create_tables`
- Criar tabela `produtos_processados`
- Criar tabela `vendas_processadas`
- Criar tabela `relatorio_vendas` (join dos dados)

#### Task 5: `load_data`
- Carregar dados transformados nas tabelas PostgreSQL
- Validar se os dados foram inseridos corretamente

#### Task 6: `generate_report`
- Gerar relat√≥rio com:
  - Total de vendas por categoria
  - Produto mais vendido
  - Canal de venda com maior receita
  - Margem de lucro m√©dia por categoria

### Parte 3: Configura√ß√£o e Execu√ß√£o
1. **Configurar a DAG:**
   - Schedule: di√°rio √†s 6h da manh√£
   - Retry: 2 tentativas
   - Email on failure: False
   - Tags: ['produtos', 'vendas', 'exercicio']

2. **Executar e validar:**
   - Executar a DAG manualmente
   - Verificar logs de cada tarefa
   - Validar dados no PostgreSQL

## üìù Estrutura das Tabelas

### `produtos_processados`
```sql
CREATE TABLE produtos_processados (
    ID_Produto VARCHAR(10),
    Nome_Produto VARCHAR(100),
    Categoria VARCHAR(50),
    Preco_Custo DECIMAL(10,2),
    Fornecedor VARCHAR(100),
    Status VARCHAR(20),
    Data_Processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### `vendas_processadas`
```sql
CREATE TABLE vendas_processadas (
    ID_Venda VARCHAR(10),
    ID_Produto VARCHAR(10),
    Quantidade_Vendida INTEGER,
    Preco_Venda DECIMAL(10,2),
    Data_Venda DATE,
    Canal_Venda VARCHAR(20),
    Receita_Total DECIMAL(10,2),
    Mes_Venda VARCHAR(7),
    Data_Processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### `relatorio_vendas`
```sql
CREATE TABLE relatorio_vendas (
    ID_Venda VARCHAR(10),
    Nome_Produto VARCHAR(100),
    Categoria VARCHAR(50),
    Quantidade_Vendida INTEGER,
    Receita_Total DECIMAL(10,2),
    Margem_Lucro DECIMAL(10,2),
    Canal_Venda VARCHAR(20),
    Mes_Venda VARCHAR(7),
    Data_Processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ‚úÖ Crit√©rios de Avalia√ß√£o

### Conceitos (30 pontos)
- [ ] Justificativa correta da escolha ETL vs ELT
- [ ] Identifica√ß√£o adequada dos problemas nos dados
- [ ] Estrat√©gia de transforma√ß√£o bem definida

### Implementa√ß√£o (50 pontos)
- [ ] DAG estruturada corretamente
- [ ] Tarefas implementadas conforme especifica√ß√£o
- [ ] Tratamento adequado de dados nulos
- [ ] C√°lculos corretos (receita, margem, etc.)
- [ ] Depend√™ncias entre tarefas bem definidas

### Execu√ß√£o (20 pontos)
- [ ] DAG executa sem erros
- [ ] Dados carregados corretamente no PostgreSQL
- [ ] Logs informativos em cada etapa
- [ ] Valida√ß√µes implementadas

## üéÅ Desafio B√¥nus (+10 pontos)
Implemente uma tarefa adicional que:
- Detecte produtos com baixa performance (menos de 2 vendas)
- Envie alerta por log
- Crie tabela `produtos_baixa_performance`

## üìö Recursos de Apoio
- Documenta√ß√£o do Pandas para transforma√ß√µes
- Airflow TaskFlow API para depend√™ncias
- PostgreSQL Hooks para conex√£o com banco
- Logs do Airflow para debugging

## üì§ Forma de Entrega

### Instru√ß√µes para Entrega
1. **Fork do Reposit√≥rio:**
   - Fa√ßa um fork deste reposit√≥rio para sua conta GitHub

2. **Estrutura da Solu√ß√£o:**
   - Crie uma pasta com seu **RA** na raiz do projeto
   - Exemplo: se seu RA √© `123456`, crie a pasta `123456/`
   - Coloque todos os arquivos da sua solu√ß√£o dentro desta pasta

3. **Arquivos Obrigat√≥rios:**
   - `pipeline_produtos_vendas.py` (sua DAG)
   - `README.md` (documenta√ß√£o da sua solu√ß√£o)
   - Arquivos CSV de dados (se modificados)

4. **Pull Request:**
   - T√≠tulo: `[RA] - [SEU_NOME_COMPLETO] - Exerc√≠cio Final`
   - Exemplo: `[123456] - Jo√£o Silva Santos - Exerc√≠cio Final`
   - Descri√ß√£o: breve resumo da sua implementa√ß√£o

### Estrutura Esperada
```
data-pipeline-workshop-airflow3/
‚îú‚îÄ‚îÄ [6324073]/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_produtos_vendas.py
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ dados/ (se necess√°rio)
‚îî‚îÄ‚îÄ ...
```

---

*Lembre-se: O objetivo √© aplicar os conceitos de pipeline de dados de forma pr√°tica. Foque na qualidade da implementa√ß√£o e na clareza do c√≥digo.*